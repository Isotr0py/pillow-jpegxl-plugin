name: Benchmarks

on:
  # Trigger the workflow on push or pull request,
  # but only for the main branch
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

env:
  RUSTFLAGS: -C debuginfo=0  # Do not produce debug symbols to keep memory usage down
  RUST_BACKTRACE: 1

jobs:
  benchmarks:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        # we only use macos for fast testing
        os: [macos-latest, windows-latest]
        python-version: ['3.13']

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Create virtual environment
        run: python -m venv venv

      - name: Set up libjxl (Windows)
        if: ${{ matrix.os == 'windows-latest' }}
        run: vcpkg install libjxl

      - name: Set up libjxl (MacOS)
        if: ${{ matrix.os == 'macos-latest' }}
        run: brew install jpeg-xl

      - name: Run benchmarks scripts (Windows)
        if: ${{ matrix.os == 'windows-latest' }}
        run: |
          venv/Scripts/activate
          python -m pip install -e . -v --config-settings=build-args="--features=dynamic"
          python benchmarks/benchmarks_encode.py -i test/images/bench.png -o benchmarks-results-${{ matrix.os }}-py${{ matrix.python-version }}.json

      - name: Run benchmarks scripts (MacOS)
        if: ${{ matrix.os == 'macos-latest' }}
        run: |
          source venv/bin/activate
          python -m pip install -e . -v
          python benchmarks/benchmarks_encode.py -i test/images/bench.png -o benchmarks-results-${{ matrix.os }}-py${{ matrix.python-version }}.json

      - name: Upload pytest test results
        uses: actions/upload-artifact@v4
        with:
          name: benchmarks-results-${{ matrix.os }}-py${{ matrix.python-version }}
          path: benchmarks-results-${{ matrix.os }}-py${{ matrix.python-version }}.json
        # Use always() to always run this step to publish test results when there are test failures
        if: ${{ always() }}


